{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Fecha          Usuario Displayed name  \\\n",
      "0  1/6/2015 21:07  GunsandCoffee70  GunsandCoffee   \n",
      "1  1/6/2015 21:27  GunsandCoffee70  GunsandCoffee   \n",
      "2  1/6/2015 21:29  GunsandCoffee70  GunsandCoffee   \n",
      "3  1/6/2015 21:37  GunsandCoffee70  GunsandCoffee   \n",
      "4  1/6/2015 21:45  GunsandCoffee70  GunsandCoffee   \n",
      "\n",
      "                                           Contenido Ubicacion        tema  \n",
      "0  'A MESSAGE TO THE TRUTHFUL IN SYRIA - SHEIKH A...       NaN  terrorismo  \n",
      "1  SHEIKH FATIH AL JAWLANI 'FOR THE PEOPLE OF INT...       NaN  terrorismo  \n",
      "2  FIRST AUDIO MEETING WITH SHEIKH FATIH AL JAWLA...       NaN  terrorismo  \n",
      "3  SHEIKH NASIR AL WUHAYSHI (HA), LEADER OF AQAP:...       NaN  terrorismo  \n",
      "4  AQAP: 'RESPONSE TO SHEIKH BAGHDADIS STATEMENT ...       NaN  terrorismo  \n",
      "                    Fecha          Usuario  \\\n",
      "4995  2019-11-29 23:59:56    SpottyBalfour   \n",
      "4996  2019-11-29 23:59:56  billiesbadhabit   \n",
      "4997  2019-11-29 23:59:56       jacewalden   \n",
      "4998  2019-11-29 23:59:56    MetroBunnyMtl   \n",
      "4999  2019-11-29 23:59:56        CBSSunday   \n",
      "\n",
      "                           Displayed name  \\\n",
      "4995  Sabrina Balfour (Parody of a Tweep)   \n",
      "4996                                 em 🦇   \n",
      "4997                          Jace Walden   \n",
      "4998                Comrade MetroBunny 🚇🐇   \n",
      "4999                 CBS Sunday Morning 🌞   \n",
      "\n",
      "                                              Contenido Ubicacion  tema  \n",
      "4995  wa indigenous land case effectively largest li...       NaN  otro  \n",
      "4996                                               good       NaN  otro  \n",
      "4997                                  go hell floridian       NaN  otro  \n",
      "4998                   nestle still us slave labour day       NaN  otro  \n",
      "4999  dying star war fan wish seeing rise skywalker ...       NaN  otro  \n",
      "\n",
      " ---------------------------------------- \n",
      "Precisión del modelo: 0.9305648582272829\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# cargar los dos sets de tweets en dataframes\n",
    "df1 = pd.read_excel('IsisFanboy.xlsx')\n",
    "df2 = pd.read_excel('randomClean.xlsx')\n",
    "\n",
    "# agregar una columna 'tema' que identifique el tema de cada set de tweets\n",
    "df1['tema'] = 'terrorismo'\n",
    "df2['tema'] = 'otro'\n",
    "\n",
    "# concatenar los dataframes\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "print(df.head())  # debug\n",
    "print(df.tail())  # debug\n",
    "\n",
    "# dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Contenido'].values.astype(str), df['tema'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# crear un vectorizador Tfidf para convertir el texto a vectores numéricos\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# crear un modelo de regresión logística\n",
    "model = LogisticRegression()\n",
    "\n",
    "# entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# predecir los temas de los tweets de prueba\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# evaluar la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('\\n ---------------------------------------- \\nPrecisión del modelo:', accuracy)\n",
    "\n",
    "# # Guardar el modelo en un archivo 'model.pkl'\n",
    "# with open('model.pkl', 'wb') as model_file:\n",
    "#     pickle.dump(model, model_file)\n",
    "\n",
    "# # Guardar el vectorizador en un archivo 'vectorizer.pkl'\n",
    "# with open('vectorizer.pkl', 'wb') as vectorizer_file:\n",
    "#     pickle.dump(vectorizer, vectorizer_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '20230315_235314_tweets.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[39m# devolver los tweets clasificados como \"terrorismo\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m [t \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(lista_tweets) \u001b[39mif\u001b[39;00m es_terrorismo[i]]\n\u001b[0;32m---> 17\u001b[0m tweets \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(\u001b[39m\"\u001b[39;49m\u001b[39m20230315_235314_tweets.xlsx\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(tweets))\n\u001b[1;32m     19\u001b[0m tweets \u001b[39m=\u001b[39m tweets[\u001b[39m'\u001b[39m\u001b[39mContenido\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UNIR/ASIGNATURAS/TFG/CodigoAPP/Project/venv_tfg/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UNIR/ASIGNATURAS/TFG/CodigoAPP/Project/venv_tfg/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UNIR/ASIGNATURAS/TFG/CodigoAPP/Project/venv_tfg/lib/python3.8/site-packages/pandas/io/excel/_base.py:482\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    481\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(io, storage_options\u001b[39m=\u001b[39;49mstorage_options, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[1;32m    483\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[1;32m    484\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    485\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    486\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UNIR/ASIGNATURAS/TFG/CodigoAPP/Project/venv_tfg/lib/python3.8/site-packages/pandas/io/excel/_base.py:1652\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m     ext \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxls\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1651\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1652\u001b[0m     ext \u001b[39m=\u001b[39m inspect_excel_format(\n\u001b[1;32m   1653\u001b[0m         content_or_path\u001b[39m=\u001b[39;49mpath_or_buffer, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[1;32m   1654\u001b[0m     )\n\u001b[1;32m   1655\u001b[0m     \u001b[39mif\u001b[39;00m ext \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1656\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1657\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExcel file format cannot be determined, you must specify \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1658\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39man engine manually.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1659\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UNIR/ASIGNATURAS/TFG/CodigoAPP/Project/venv_tfg/lib/python3.8/site-packages/pandas/io/excel/_base.py:1525\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(content_or_path, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1523\u001b[0m     content_or_path \u001b[39m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1525\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m   1526\u001b[0m     content_or_path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m, storage_options\u001b[39m=\u001b[39;49mstorage_options, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m   1527\u001b[0m ) \u001b[39mas\u001b[39;00m handle:\n\u001b[1;32m   1528\u001b[0m     stream \u001b[39m=\u001b[39m handle\u001b[39m.\u001b[39mhandle\n\u001b[1;32m   1529\u001b[0m     stream\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UNIR/ASIGNATURAS/TFG/CodigoAPP/Project/venv_tfg/lib/python3.8/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    866\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '20230315_235314_tweets.xlsx'"
     ]
    }
   ],
   "source": [
    "#### ESTA FUNCIÓN HA SIDO YA IMPLEMENTADA EN EL FICHERO PROTOTIPO ####\n",
    "# SOLO PARA DEBUGGING #\n",
    "\n",
    "def clasificar_tweets(lista_tweets):\n",
    "    # crear vectores numéricos a partir del texto de los tweets\n",
    "    lista_vec = vectorizer.transform(lista_tweets)\n",
    "\n",
    "    # hacer predicciones de la clase de los tweets\n",
    "    predicciones = model.predict(lista_vec)\n",
    "\n",
    "    # identificar cuáles tweets son de la categoría \"es_terrorismo\"\n",
    "    es_terrorismo = predicciones == 'otro'\n",
    "\n",
    "    # devolver los tweets clasificados como \"terrorismo\"\n",
    "    return [t for i, t in enumerate(lista_tweets) if es_terrorismo[i]]\n",
    "\n",
    "tweets = pd.read_excel(\"20230315_235314_tweets.xlsx\")\n",
    "print(len(tweets))\n",
    "tweets = tweets['Contenido'].values.astype(str)\n",
    "tweets_terrorismo = clasificar_tweets(tweets)\n",
    "print(len(tweets_terrorismo))\n",
    "\n",
    "for i, tweet in enumerate(tweets_terrorismo, start=1):\n",
    "    print(f\"{i}. {tweet}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
